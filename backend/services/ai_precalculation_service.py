"""
Service de pr√©calcul des pr√©dictions IA
Calcule et stocke les pr√©dictions pour toutes les communes toutes les heures
"""

import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Any
from pymongo import MongoClient
import os
import sys
import logging

# Ajouter le chemin parent pour importer les modules
sys.path.append('/app/backend')

from ai_models.cyclone_damage_predictor import CycloneDamagePredictor
from data.communes_data import COMMUNES_GUADELOUPE

# Convertir le dictionnaire en liste pour compatibilit√©
GUADELOUPE_COMMUNES = [
    {"name": name, **data} for name, data in COMMUNES_GUADELOUPE.items()
]

logger = logging.getLogger(__name__)

class AIPrecalculationService:
    def __init__(self):
        mongo_url = os.environ.get('MONGO_URL', 'mongodb://localhost:27017')
        self.client = MongoClient(mongo_url)
        self.db = self.client.weather_db
        
        # Collections pour les pr√©dictions pr√©calcul√©es
        self.predictions_collection = self.db.ai_predictions
        self.global_risk_collection = self.db.ai_global_risk
        
        # Index pour optimiser les requ√™tes
        self.predictions_collection.create_index([("commune", 1), ("calculated_at", -1)])
        self.global_risk_collection.create_index("calculated_at", expireAfterSeconds=7200)  # 2h
        
        # Initialiser le mod√®le IA
        self.predictor = CycloneDamagePredictor()
        
        logger.info("AIPrecalculationService initialized")
    
    async def precalculate_all_predictions(self):
        """Pr√©calcule toutes les pr√©dictions pour toutes les communes"""
        try:
            logger.info("ü§ñ D√©but du pr√©calcul IA pour toutes les communes...")
            start_time = datetime.utcnow()
            
            # Calculer les pr√©dictions pour chaque commune
            predictions_data = []
            
            for i, commune in enumerate(GUADELOUPE_COMMUNES):
                try:
                    logger.info(f"üìä Calcul IA {i+1}/{len(GUADELOUPE_COMMUNES)}: {commune['name']}")
                    
                    # Pr√©dictions de dommages
                    prediction_result = await self._calculate_commune_prediction(commune)
                    
                    # Timeline
                    timeline_result = await self._calculate_commune_timeline(commune)
                    
                    # Historique
                    historical_result = await self._calculate_commune_historical(commune)
                    
                    # Stocker dans la collection
                    prediction_document = {
                        "commune": commune['name'],
                        "coordinates": commune['coordinates'],
                        "prediction": prediction_result,
                        "timeline": timeline_result,
                        "historical": historical_result,
                        "calculated_at": start_time,
                        "expires_at": start_time + timedelta(hours=2)  # Expire dans 2h
                    }
                    
                    predictions_data.append(prediction_document)
                    
                except Exception as e:
                    logger.error(f"‚ùå Erreur calcul pour {commune['name']}: {e}")
                    continue
            
            # Sauvegarder toutes les pr√©dictions
            if predictions_data:
                # Supprimer les anciennes pr√©dictions
                self.predictions_collection.delete_many({
                    "calculated_at": {"$lt": start_time}
                })
                
                # Ins√©rer les nouvelles
                result = self.predictions_collection.insert_many(predictions_data)
                logger.info(f"‚úÖ {len(result.inserted_ids)} pr√©dictions sauvegard√©es")
            
            # Calculer le risque global
            await self._calculate_global_risk(start_time)
            
            duration = (datetime.utcnow() - start_time).total_seconds()
            logger.info(f"üéØ Pr√©calcul termin√© en {duration:.2f}s")
            
            return {
                "success": True,
                "communes_processed": len(predictions_data),
                "duration_seconds": duration,
                "timestamp": start_time
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©calcul global: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.utcnow()
            }
    
    async def _calculate_commune_prediction(self, commune):
        """Calcule les pr√©dictions de dommages pour une commune"""
        try:
            # Simuler des conditions m√©t√©o moyennes pour le pr√©calcul
            weather_conditions = {
                'wind_speed': 45.0,  # km/h
                'pressure': 990.0,   # hPa  
                'temperature': 28.0, # ¬∞C
                'humidity': 75.0,    # %
                'precipitation': 15.0 # mm/h
            }
            
            damage_prediction = self.predictor.predict_damage(
                commune_name=commune['name'],
                coordinates=commune['coordinates'],
                weather_conditions=weather_conditions,
                population=commune.get('population', 10000)
            )
            
            return {
                "commune": commune['name'],
                "coordinates": commune['coordinates'],
                "damage_predictions": damage_prediction['damage_predictions'],
                "risk_level": damage_prediction['risk_level'],
                "confidence_score": damage_prediction['confidence_score'],
                "recommendations": damage_prediction['recommendations'],
                "weather_conditions": weather_conditions
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur pr√©diction {commune['name']}: {e}")
            return None
    
    async def _calculate_commune_timeline(self, commune):
        """Calcule la timeline de pr√©dictions pour une commune"""
        try:
            timeline_data = {}
            
            # G√©n√©rer une timeline H+0 √† H+24
            for hour in range(0, 25, 6):  # Toutes les 6h
                hour_key = f"H+{hour}"
                
                # Progression du risque dans le temps
                risk_factor = min(1.0, hour / 12)  # Pic √† H+12
                
                timeline_data[hour_key] = {
                    "commune": commune['name'],
                    "coordinates": commune['coordinates'],
                    "hour": hour,
                    "risk_evolution": {
                        "wind_risk": round(risk_factor * 65, 1),
                        "flood_risk": round(risk_factor * 45, 1),
                        "infrastructure_risk": round(risk_factor * 35, 1)
                    },
                    "recommended_actions": self._get_timeline_recommendations(hour, risk_factor)
                }
            
            return {
                "commune": commune['name'],
                "coordinates": commune['coordinates'],
                "timeline_predictions": timeline_data
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur timeline {commune['name']}: {e}")
            return None
    
    async def _calculate_commune_historical(self, commune):
        """G√©n√®re les donn√©es historiques pour une commune"""
        try:
            # Donn√©es historiques simul√©es bas√©es sur la localisation
            historical_events = []
            
            # √âv√©nements majeurs de Guadeloupe
            major_events = [
                {"year": 2017, "name": "Ouragan Irma", "category": 5},
                {"year": 2020, "name": "Temp√™te Laura", "category": 2}, 
                {"year": 2019, "name": "Temp√™te Karen", "category": 1},
                {"year": 2010, "name": "Ouragan Earl", "category": 4},
                {"year": 1999, "name": "Ouragan Lenny", "category": 4}
            ]
            
            for event in major_events:
                # Impact bas√© sur la position g√©ographique
                is_coastal = commune.get('type', '') == 'c√¥ti√®re'
                base_damage = 15 if is_coastal else 8
                
                historical_events.append({
                    "year": event["year"],
                    "event_name": event["name"],
                    "damage_type": "infrastructure",
                    "damage_percentage": base_damage + (event["category"] * 3),
                    "recovery_time_days": event["category"] * 30,
                    "economic_impact_euros": event["category"] * 2000000
                })
            
            return {
                "commune": commune['name'],
                "coordinates": commune['coordinates'],
                "historical_events": historical_events,
                "risk_factors": commune.get('riskFactors', []),
                "vulnerability_score": min(100, len(commune.get('riskFactors', [])) * 25)
            }
            
        except Exception as e:
            logger.error(f"‚ùå Erreur historique {commune['name']}: {e}")
            return None
    
    async def _calculate_global_risk(self, timestamp):
        """Calcule le risque global bas√© sur toutes les pr√©dictions"""
        try:
            # Compter les communes par niveau de risque
            pipeline = [
                {"$match": {"calculated_at": timestamp}},
                {"$group": {
                    "_id": "$prediction.risk_level",
                    "count": {"$sum": 1},
                    "communes": {"$push": "$commune"}
                }}
            ]
            
            risk_counts = list(self.predictions_collection.aggregate(pipeline))
            
            # Calculer les statistiques
            high_risk_count = 0
            critical_risk_count = 0
            affected_communes = []
            
            for risk_group in risk_counts:
                risk_level = risk_group["_id"]
                count = risk_group["count"]
                communes = risk_group["communes"]
                
                if risk_level in ['√©lev√©', 'critique']:
                    high_risk_count += count
                    affected_communes.extend(communes)
                    
                if risk_level == 'critique':
                    critical_risk_count += count
            
            # D√©terminer le niveau de risque global
            total_communes = len(GUADELOUPE_COMMUNES)
            risk_percentage = (high_risk_count / total_communes) * 100
            
            if risk_percentage > 50:
                global_risk_level = "critique"
            elif risk_percentage > 25:
                global_risk_level = "√©lev√©"
            elif risk_percentage > 10:
                global_risk_level = "mod√©r√©"
            else:
                global_risk_level = "faible"
            
            # Sauvegarder le risque global
            global_risk_doc = {
                "global_risk_level": global_risk_level,
                "affected_communes": affected_communes,
                "high_risk_count": high_risk_count,
                "critical_risk_count": critical_risk_count,
                "total_communes": total_communes,
                "risk_percentage": round(risk_percentage, 1),
                "regional_recommendations": self._get_regional_recommendations(global_risk_level),
                "calculated_at": timestamp,
                "last_analysis": timestamp
            }
            
            # Supprimer l'ancien et ins√©rer le nouveau
            self.global_risk_collection.delete_many({})
            self.global_risk_collection.insert_one(global_risk_doc)
            
            logger.info(f"‚úÖ Risque global calcul√©: {global_risk_level} ({risk_percentage:.1f}%)")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur calcul risque global: {e}")
    
    def _get_timeline_recommendations(self, hour, risk_factor):
        """G√©n√®re des recommandations bas√©es sur l'heure et le facteur de risque"""
        if hour == 0:
            return ["V√©rifier les provisions d'urgence", "S√©curiser les objets ext√©rieurs"]
        elif hour <= 6:
            return ["√âviter les d√©placements non essentiels", "Surveiller les bulletins m√©t√©o"]
        elif hour <= 12:
            return ["Rester √† l'int√©rieur", "√âviter les zones inondables"]
        else:
            return ["Attendre les consignes officielles", "V√©rifier l'√©tat des infrastructures"]
    
    def _get_regional_recommendations(self, risk_level):
        """G√©n√®re des recommandations r√©gionales"""
        recommendations = {
            "faible": [
                "Maintenir la surveillance m√©t√©orologique",
                "V√©rifier les syst√®mes d'alerte"
            ],
            "mod√©r√©": [
                "Pr√©parer les plans d'√©vacuation",
                "Alerter les services d'urgence"
            ],
            "√©lev√©": [
                "Activer les centres d'h√©bergement",
                "Mobiliser les √©quipes de secours"
            ],
            "critique": [
                "D√©clencher l'√©tat d'urgence",
                "√âvacuation pr√©ventive des zones √† risque"
            ]
        }
        return recommendations.get(risk_level, [])
    
    async def get_cached_prediction(self, commune_name: str):
        """R√©cup√®re une pr√©diction pr√©calcul√©e pour une commune"""
        try:
            # Chercher la pr√©diction la plus r√©cente
            prediction = self.predictions_collection.find_one(
                {"commune": commune_name},
                sort=[("calculated_at", -1)]
            )
            
            if prediction and prediction['expires_at'] > datetime.utcnow():
                # Supprimer l'_id de MongoDB
                if '_id' in prediction:
                    del prediction['_id']
                return prediction['prediction']
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration cache {commune_name}: {e}")
            return None
    
    async def get_cached_timeline(self, commune_name: str):
        """R√©cup√®re une timeline pr√©calcul√©e pour une commune"""
        try:
            prediction = self.predictions_collection.find_one(
                {"commune": commune_name},
                sort=[("calculated_at", -1)]
            )
            
            if prediction and prediction['expires_at'] > datetime.utcnow():
                if '_id' in prediction:
                    del prediction['_id']
                return prediction['timeline']
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration timeline {commune_name}: {e}")
            return None
    
    async def get_cached_historical(self, commune_name: str):
        """R√©cup√®re les donn√©es historiques pr√©calcul√©es pour une commune"""
        try:
            prediction = self.predictions_collection.find_one(
                {"commune": commune_name},
                sort=[("calculated_at", -1)]
            )
            
            if prediction and prediction['expires_at'] > datetime.utcnow():
                if '_id' in prediction:
                    del prediction['_id']
                return prediction['historical']
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration historique {commune_name}: {e}")
            return None
    
    async def get_cached_global_risk(self):
        """R√©cup√®re le risque global pr√©calcul√©"""
        try:
            global_risk = self.global_risk_collection.find_one(
                {},
                sort=[("calculated_at", -1)]
            )
            
            if global_risk:
                if '_id' in global_risk:
                    del global_risk['_id']
                return global_risk
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Erreur r√©cup√©ration risque global: {e}")
            return None

# Instance globale
ai_precalculation_service = None

async def get_ai_precalculation_service():
    """Retourne l'instance du service de pr√©calcul IA"""
    global ai_precalculation_service
    if ai_precalculation_service is None:
        ai_precalculation_service = AIPrecalculationService()
    return ai_precalculation_service